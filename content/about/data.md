---
title: Data Security
---

# Data Security

Unless it's required of us to investigate a reported instance of abuse of our policies, under standard operation our moderators have no ability to access your private mentions with other members of our Mastodon platform. Due in part to the open and federated nature of Mastodon instances, the Mastodon administrators of other instances you interact with may have access to your data and messages delivered to their servers.

While the connection to this site is encrypted, this is only the data in transit to you and to other servers in the federated network.
**The messages and data stored in the instance is not encrypted.**

This is not a choice of the administrator, but a limitation of the Mastodon platform.
While our server administrators do have access to these messages through raw database access, this is not done except under the circumstances outlined above.
Where possible, we will notify you if such processes are taken for data associated by your account.

Additionally, our hosting providers may have access to your data as part of the general administration of the server infrastructure, subject to their own Terms of Service.

You should use [Signal](https://www.signal.org/), [Matrix](https://joinmatrix.org/), or another end-to-end encrypted messaging platform for communications that you want to be secured and visible only to you and the intended party.

## Privacy Policy

Please review our full [Privacy Policy](/about/tos) for more information.

## Large Language Models

A large language model, like ChatGPT, is a type of "artificial intelligence" program designed to understand and generate human-like text by processing vast amounts of written language.
While the creation and use of large language models are not inherently unethical or illegal, there are many important questions about how companies obtain their data to train their models and how that data is used.

vmst.io has taken some steps to limit organizations who build these models from accessing your public post data.
In some cases this involves directly blocking the accessiblity of third-parties to our site through firewalls, but in most cases this is done by requesting that they not index our site through user agent flags in our [robots.txt](https://vmst.io/robots.txt) file.